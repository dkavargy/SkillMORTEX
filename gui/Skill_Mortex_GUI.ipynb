{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AciWq9H75Dpu"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Install required packages\n",
        "!pip install -q streamlit pyngrok pandas\n",
        "\n",
        "# STEP 2: Set your ngrok authtoken\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2wbDASVryYnzh5OPDUJVzSfLLKM_6xcoryMdVGs9uoRDvsss5\")\n",
        "\n",
        "# STEP 3: Write a simple Streamlit app that loads your CSV\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"ðŸ“Š Skill Epidemiology Dashboard\")\n",
        "\n",
        "# Load your metrics\n",
        "df = pd.read_csv(\"/content/sample_data/epidemiological_skill_metrics.csv\")\n",
        "\n",
        "# Filters\n",
        "revived = st.selectbox(\"Filter by Revived?\", options=[\"All\", \"Yes\", \"No\"])\n",
        "mortality = st.selectbox(\"Filter by Mortality Risk\", options=[\"All\", \"ðŸŸ¢\", \"ðŸ”µ\"])\n",
        "\n",
        "if revived != \"All\":\n",
        "    df = df[df[\"Revived?\"] == revived]\n",
        "if mortality != \"All\":\n",
        "    df = df[df[\"Mortality Risk\"] == mortality]\n",
        "\n",
        "# Display table\n",
        "st.dataframe(df)\n",
        "\n",
        "# Plot: Top skills by Incidence\n",
        "st.subheader(\"Top 10 Skills by Incidence (2023)\")\n",
        "top = df.sort_values(by=\"Incidence (2023)\", ascending=False).head(10)\n",
        "st.bar_chart(top.set_index(\"Skill\")[\"Incidence (2023)\"])\n",
        "\"\"\")\n",
        "\n",
        "# STEP 4: Start Streamlit in background\n",
        "!streamlit run app.py &>/content/log.txt &\n",
        "\n",
        "# STEP 5: Open the public URL via ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"âœ… Streamlit app is live: {public_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # STEP 1: Install required packages\n",
        "# !pip install -q streamlit pyngrok pandas\n",
        "from pyngrok import ngrok\n",
        "import pandas as pd\n",
        "\n",
        "# Set your ngrok token\n",
        "ngrok.set_auth_token(\"2wbDASVryYnzh5OPDUJVzSfLLKM_6xcoryMdVGs9uoRDvsss5\")\n",
        "\n",
        "# Create Streamlit app\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"ðŸ“Š Skill Epidemiology Dashboard\")\n",
        "\n",
        "# Load metrics CSV\n",
        "df = pd.read_csv(\"/content/sample_data/epidemiological_skill_metrics.csv\")\n",
        "\n",
        "# === Filters ===\n",
        "st.sidebar.header(\"Filter\")\n",
        "revived_filter = st.sidebar.selectbox(\"Show Revived?\", [\"All\", \"Yes\", \"No\"])\n",
        "mortality_filter = st.sidebar.selectbox(\"Mortality Risk\", [\"All\", \"ðŸŸ¢\", \"ðŸ”µ\"])\n",
        "\n",
        "if revived_filter != \"All\":\n",
        "    df = df[df[\"Revived?\"] == revived_filter]\n",
        "if mortality_filter != \"All\":\n",
        "    df = df[df[\"Mortality Risk\"] == mortality_filter]\n",
        "\n",
        "# === Main Table ===\n",
        "st.subheader(\"ðŸ§  Filtered Skill Epidemiology Table\")\n",
        "st.dataframe(df)\n",
        "\n",
        "# === Charts ===\n",
        "st.subheader(\"ðŸ“ˆ Top 10 Skills by Incidence (2023)\")\n",
        "st.bar_chart(df.sort_values(by=\"Incidence (2023)\", ascending=False).head(10).set_index(\"Skill\")[\"Incidence (2023)\"])\n",
        "\n",
        "st.subheader(\"ðŸ“‰ Skills with Largest Decline\")\n",
        "st.bar_chart(df.sort_values(by=\"% Change in Incidence\").head(10).set_index(\"Skill\")[\"% Change in Incidence\"])\n",
        "\n",
        "st.subheader(\"â™»ï¸ Revived Skills\")\n",
        "revived_df = df[df[\"Revived?\"] == \"Yes\"]\n",
        "if not revived_df.empty:\n",
        "    st.bar_chart(revived_df.sort_values(by=\"Incidence (2023)\", ascending=False).head(10).set_index(\"Skill\")[\"Incidence (2023)\"])\n",
        "else:\n",
        "    st.write(\"No revived skills to show.\")\n",
        "\n",
        "# === Insights ===\n",
        "st.subheader(\"ðŸ“‰ Dying but Historically Popular Skills\")\n",
        "dying_popular = df[(df[\"Mortality Risk\"] == \"ðŸŸ¢\") & (df[\"Total Posts\"] > 500)]\n",
        "st.dataframe(dying_popular.sort_values(by=\"Total Posts\", ascending=False).head(10))\n",
        "\n",
        "st.subheader(\"ðŸŸ¦ Growing & Alive Skills\")\n",
        "survivors = df[(df[\"Mortality Risk\"] == \"ðŸ”µ\") & (df[\"% Change in Incidence\"] > 0)]\n",
        "st.dataframe(survivors.sort_values(by=\"% Change in Incidence\", ascending=False).head(10))\n",
        "\n",
        "# === Bubble Chart ===\n",
        "st.subheader(\"ðŸ§ª Incidence vs Popularity (Bubble Chart)\")\n",
        "bubble = alt.Chart(df).mark_circle(size=80).encode(\n",
        "    x='Incidence (2023):Q',\n",
        "    y='Total Posts:Q',\n",
        "    color='Mortality Risk:N',\n",
        "    tooltip=['Skill', 'Incidence (2023)', 'Total Posts', 'Mortality Risk']\n",
        ").interactive().properties(height=400)\n",
        "st.altair_chart(bubble, use_container_width=True)\n",
        "\n",
        "# === Download Button ===\n",
        "csv = df.to_csv(index=False).encode('utf-8')\n",
        "st.download_button(\"ðŸ’¾ Download Filtered Metrics\", csv, \"filtered_skills.csv\", \"text/csv\")\n",
        "\"\"\")\n",
        "\n",
        "# Run Streamlit in background\n",
        "!streamlit run app.py &>/content/log.txt &\n",
        "\n",
        "# Open public tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"âœ… Your Streamlit dashboard is live: {public_url}\")\n"
      ],
      "metadata": {
        "id": "CLLyhLpJ5GeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "\n",
        "# Set your ngrok token\n",
        "ngrok.set_auth_token(\"2wbDASVryYnzh5OPDUJVzSfLLKM_6xcoryMdVGs9uoRDvsss5\")\n",
        "\n",
        "# === Write Streamlit App ===\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "import json\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"ðŸ§¬ Skill Biology Dashboard\")\n",
        "\n",
        "# === Load and process JSON ===\n",
        "with open(\"/content/sample_data/Posts.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "posts = data['posts']['row']\n",
        "skill_data = defaultdict(list)\n",
        "\n",
        "for post in posts:\n",
        "    tags_str = post.get('@Tags', '')\n",
        "    tags = tags_str.strip('|').split('|') if tags_str else []\n",
        "    creation_date_str = post.get('@CreationDate')\n",
        "    view_count = int(post.get('@ViewCount', 0))\n",
        "    score = int(post.get('@Score', 0))\n",
        "    answer_count = int(post.get('@AnswerCount', 0))\n",
        "\n",
        "    if creation_date_str:\n",
        "        creation_date = datetime.strptime(creation_date_str, '%Y-%m-%dT%H:%M:%S.%f')\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    for tag in tags:\n",
        "        skill_data[tag].append({\n",
        "            'creation_date': creation_date,\n",
        "            'view_count': view_count,\n",
        "            'score': score,\n",
        "            'answer_count': answer_count\n",
        "        })\n",
        "\n",
        "metrics = []\n",
        "for skill, entries in skill_data.items():\n",
        "    dates = [entry['creation_date'] for entry in entries]\n",
        "    views = [entry['view_count'] for entry in entries]\n",
        "    scores = [entry['score'] for entry in entries]\n",
        "    answers = [entry['answer_count'] for entry in entries]\n",
        "\n",
        "    date_of_birth = min(dates).date()\n",
        "    df = pd.DataFrame(entries)\n",
        "    df['month'] = df['creation_date'].dt.to_period('M')\n",
        "    peak_month = df.groupby('month').size().idxmax().strftime('%Y-%m')\n",
        "\n",
        "    avg_views = sum(views) / len(views) if views else 0\n",
        "    avg_score = sum(scores) / len(scores) if scores else 0\n",
        "    avg_answers = sum(answers) / len(answers) if answers else 0\n",
        "    total_posts = len(entries)\n",
        "\n",
        "    if avg_score >= 10 and avg_answers >= 3:\n",
        "        immunity = 'High'\n",
        "    elif avg_score >= 5:\n",
        "        immunity = 'Medium'\n",
        "    else:\n",
        "        immunity = 'Low'\n",
        "\n",
        "    metrics.append({\n",
        "        'Skill': skill,\n",
        "        'Date of Birth': date_of_birth,\n",
        "        'Peak Activity Date': peak_month,\n",
        "        'Avg Views': round(avg_views, 2),\n",
        "        'Avg Score': round(avg_score, 2),\n",
        "        'Avg Answers': round(avg_answers, 2),\n",
        "        'Total Posts': total_posts,\n",
        "        'Immunity Score': immunity\n",
        "    })\n",
        "\n",
        "df_metrics = pd.DataFrame(metrics)\n",
        "\n",
        "# === Dashboard ===\n",
        "st.subheader(\"ðŸ“‹ Skill Biology Table\")\n",
        "st.dataframe(df_metrics)\n",
        "\n",
        "st.subheader(\"ðŸ”¥ Top Skills by Total Posts\")\n",
        "top_skills = df_metrics.sort_values(by='Total Posts', ascending=False).head(10)\n",
        "st.bar_chart(top_skills.set_index(\"Skill\")[\"Total Posts\"])\n",
        "\n",
        "st.subheader(\"ðŸ§ª Views vs. Score (Bubble Chart)\")\n",
        "chart = alt.Chart(df_metrics).mark_circle(size=80).encode(\n",
        "    x='Avg Views',\n",
        "    y='Avg Score',\n",
        "    color='Immunity Score',\n",
        "    tooltip=['Skill', 'Avg Views', 'Avg Score', 'Avg Answers', 'Total Posts']\n",
        ").interactive()\n",
        "st.altair_chart(chart, use_container_width=True)\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# Launch public URL\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"âœ… Your Skill Biology Dashboard is live: {public_url}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qGOlcYD05H9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit app to show inverse trend analysis between skills (no survival model)\n",
        "\n",
        "!pip install -q streamlit pyngrok pandas altair scikit-learn\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from itertools import combinations\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import altair as alt\n",
        "\n",
        "# Set ngrok token\n",
        "ngrok.set_auth_token(\"2wbDASVryYnzh5OPDUJVzSfLLKM_6xcoryMdVGs9uoRDvsss5\")\n",
        "\n",
        "# === Write app.py ===\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from itertools import combinations\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import altair as alt\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"ðŸ” Skill Trend Inversion Dashboard\")\n",
        "\n",
        "# === Load JSON ===\n",
        "with open(\"/content/sample_data/Posts.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "posts = data['posts']['row']\n",
        "tag_dates = defaultdict(list)\n",
        "\n",
        "# === Extract tag dates ===\n",
        "for post in posts:\n",
        "    try:\n",
        "        date = datetime.strptime(post[\"@CreationDate\"], \"%Y-%m-%dT%H:%M:%S.%f\")\n",
        "        tags = re.findall(r'\\\\|([^|]+)\\\\|', post.get(\"@Tags\", \"\"))\n",
        "        for tag in tags:\n",
        "            tag_dates[tag].append(date)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "# === Top 100 tags ===\n",
        "tag_counts = {tag: len(dates) for tag, dates in tag_dates.items()}\n",
        "top_100_tags = sorted(tag_counts, key=tag_counts.get, reverse=True)[:100]\n",
        "\n",
        "# === Monthly series ===\n",
        "tag_series = {}\n",
        "for tag in top_100_tags:\n",
        "    s = pd.Series(1, index=pd.to_datetime(tag_dates[tag]))\n",
        "    s = s.resample(\"M\").sum().fillna(0)\n",
        "    tag_series[tag] = s\n",
        "\n",
        "combined_index = pd.date_range(start=\"2008-01-01\", end=\"2024-12-31\", freq=\"M\")\n",
        "for tag in tag_series:\n",
        "    tag_series[tag] = tag_series[tag].reindex(combined_index, fill_value=0)\n",
        "\n",
        "# === UI: Pick skills to compare ===\n",
        "st.sidebar.header(\"ðŸ§  Skill Selection\")\n",
        "tag1 = st.sidebar.selectbox(\"Select Declining Skill\", top_100_tags)\n",
        "tag2 = st.sidebar.selectbox(\"Select Competing Skill\", [t for t in top_100_tags if t != tag1])\n",
        "\n",
        "# === Regression Function ===\n",
        "def get_slope(ts):\n",
        "    X = np.arange(len(ts)).reshape(-1, 1)\n",
        "    y = ts.values.reshape(-1, 1)\n",
        "    model = LinearRegression().fit(X, y)\n",
        "    return model.coef_[0][0]\n",
        "\n",
        "# === Process Selected Pair ===\n",
        "s1 = tag_series[tag1]\n",
        "s2 = tag_series[tag2]\n",
        "mask = (s1 > 0) & (s2 > 0)\n",
        "overlap = mask.sum()\n",
        "\n",
        "if overlap < 6:\n",
        "    st.warning(\"âŒ Not enough overlap between skills for comparison (min 6 months).\")\n",
        "else:\n",
        "    slope1 = get_slope(s1[mask])\n",
        "    slope2 = get_slope(s2[mask])\n",
        "\n",
        "    st.markdown(f\"### {tag1} vs {tag2} â€” {overlap} months overlap\")\n",
        "    st.markdown(f\"**{tag1} slope**: {slope1:.3f}, **{tag2} slope**: {slope2:.3f}\")\n",
        "\n",
        "    chart_df = pd.DataFrame({\n",
        "        \"Date\": combined_index,\n",
        "        tag1: s1.values,\n",
        "        tag2: s2.values\n",
        "    })\n",
        "    chart_df = chart_df.melt(\"Date\", var_name=\"Skill\", value_name=\"Posts\")\n",
        "\n",
        "    chart = alt.Chart(chart_df).mark_line().encode(\n",
        "        x='Date:T', y='Posts:Q', color='Skill:N'\n",
        "    ).properties(height=400)\n",
        "\n",
        "    st.altair_chart(chart, use_container_width=True)\n",
        "\"\"\")\n",
        "\n",
        "# === Launch app ===\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"âœ… Streamlit Trend Inversion App is live: {public_url}\")\n"
      ],
      "metadata": {
        "id": "BqAFdQMp5KNw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}